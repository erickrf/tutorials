{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for illustrating Sparsemax\n",
    "========\n",
    "\n",
    "This code is intended to exemplify and help understanding the sparsemax operations, as defined in the [paper](https://arxiv.org/abs/1602.02068) \"From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification\" by André Martins and Ramón Fernandez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proposition 1** defines $k(z)$ as:\n",
    "\n",
    "$k(z) = max(k \\in \\{1, 2, ..., K\\} | 1 + kz_{(k)} > \\sum_{j \\leq k} z_{(j)})$\n",
    "\n",
    "where $z \\in \\mathbb{R}^K$ and $\\{z_{(1)}, z_{(2)}, ..., z_{(K)}\\}$ is a list of the ordered elements in z.\n",
    "\n",
    "Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.44828998 -0.8733298   0.06289572  1.62920888  3.22873505 -2.08432584\n",
      " -1.01466484  3.8326466  -3.37218107  4.65226222]\n",
      "[4.652262215877265, 3.832646599074419, 3.2287350512536506, 2.4482899814934553, 1.6292088802445157, 0.06289571927698834, -0.8733298042918101, -1.0146648437284456, -2.084325841272495, -3.3721810696340593]\n"
     ]
    }
   ],
   "source": [
    "K = 10\n",
    "z = np.random.uniform(-5, 5, K)\n",
    "z_sorted = sorted(z, reverse=True)\n",
    "\n",
    "print(z)\n",
    "print(z_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first part of the inequality inside the *max*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.65226222,   8.6652932 ,  10.68620515,  10.79315993,\n",
       "         9.1460444 ,   1.37737432,  -5.11330863,  -7.11731875,\n",
       "       -17.75893257, -32.7218107 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# range starting from 1\n",
    "k_range = np.arange(1, len(z) + 1)\n",
    "1 + k_range * z_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the second one, the cumulative sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.65226222,  8.48490881, 11.71364387, 14.16193385, 15.79114273,\n",
       "       15.85403845, 14.98070864, 13.9660438 , 11.88171796,  8.50953689])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(z_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "inds = 1 + k_range * z_sorted > np.cumsum(z_sorted)\n",
    "print(inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k(z):\n",
    "    z_sorted = sorted(z, reverse=True)\n",
    "    \n",
    "    # range starting from 1\n",
    "    k_range = np.arange(1, len(z) + 1)\n",
    "    inds = 1 + k_range * z_sorted > np.cumsum(z_sorted)\n",
    "    \n",
    "    # we know the last element in k_range[inds] is the max \n",
    "    # because k_range is already ordered\n",
    "    max_ind = k_range[inds][-1]\n",
    "    return max_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it for some distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "distributions = [np.random.normal(0, 1, K),\n",
    "                 np.random.normal(0, 10, K),\n",
    "                 np.random.gamma(1, size=K),\n",
    "                 np.random.gamma(10, size=K)]\n",
    "for dist in distributions:\n",
    "    print(k(dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the $\\tau(z)$ function:\n",
    "\n",
    "$\\tau(z) = \\frac{(\\sum_{j \\leq k(z)} z_{(j)}) - 1}{k(z)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tau(z):\n",
    "    k_value = k(z)\n",
    "    \n",
    "    # we are repeating this call here; an optimized version should avoid it\n",
    "    z_sorted = np.sort(z)[::-1]\n",
    "    \n",
    "    # recall that k starts from 1\n",
    "    sum_minus_1 = z_sorted[:k_value].sum() - 1\n",
    "    return sum_minus_1 / k_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z: [ 1.939607    1.1502079  -0.88095171 -0.67453557 -0.52282631 -0.85172683\n",
      " -0.4600404  -1.32632804 -2.35361093  0.20246752]\n",
      "tau(z): 1.0449074461701429\n",
      "\n",
      "z: [ 12.54312349  -7.53803208   2.52981906   1.25311422  -3.85766725\n",
      "  15.67246015  -0.06798676  -4.20733613   4.387767   -12.74671914]\n",
      "tau(z): 14.672460153704167\n",
      "\n",
      "z: [4.35197807 0.16903238 0.4451037  0.24514015 0.22523818 3.37137648\n",
      " 1.34018159 0.08429251 2.16652902 0.20441061]\n",
      "tau(z): 3.3616772751717097\n",
      "\n",
      "z: [10.96969989  6.39395072  9.9947205  11.68669685  4.44256289 12.30690624\n",
      "  7.58271533  7.6362838   6.86791408  7.6610175 ]\n",
      "tau(z): 11.496801543924576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dist in distributions:\n",
    "    print('z:', dist)\n",
    "    print('tau(z):', tau(dist))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effectively computing sparsemax\n",
    "\n",
    "Now let's call our just implemented $\\tau(z)$ to compute the sparsemax of some distributions and compare it with their softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    exps = np.exp(z)\n",
    "    return exps / exps.sum()\n",
    "\n",
    "def sparsemax(z):\n",
    "    return np.maximum(z - tau(z), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax:  [0.48730979 0.22129595 0.02903034 0.03568596 0.0415321  0.02989126\n",
      " 0.04422334 0.01859634 0.00665709 0.08577783]\n",
      "Sparsemax:  [0.89469955 0.10530045 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "\n",
      "Softmax:  [4.19126249e-02 7.96544068e-11 1.87768182e-06 5.23788710e-07\n",
      " 3.15916236e-09 9.58072791e-01 1.39768489e-07 2.22696134e-09\n",
      " 1.20370077e-05 4.35617944e-13]\n",
      "Sparsemax:  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "\n",
      "Softmax:  [0.61181362 0.0093323  0.01229943 0.01007029 0.00987186 0.22948234\n",
      " 0.03010319 0.00857407 0.06878451 0.00966837]\n",
      "Sparsemax:  [0.9903008 0.        0.        0.        0.        0.0096992 0.\n",
      " 0.        0.        0.       ]\n",
      "\n",
      "Softmax:  [1.35718116e-01 1.39770400e-03 5.11928909e-02 2.77987743e-01\n",
      " 1.98581252e-04 5.16867424e-01 4.58869425e-03 4.84120650e-03\n",
      " 2.24519921e-03 4.96244056e-03]\n",
      "Sparsemax:  [0.         0.         0.         0.18989531 0.         0.81010469\n",
      " 0.         0.         0.         0.        ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dist in distributions:\n",
    "    print('Softmax: ', softmax(dist))\n",
    "    print('Sparsemax: ', sparsemax(dist))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
